import os
import requests
import logging
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from playwright.async_api import async_playwright, Page
from .log_service import LogService

class EnrichmentService:
    def __init__(self):
        load_dotenv()
        self.brave_token = os.getenv('BRAVE_SEARCH_TOKEN')
        self.logger = logging.getLogger(__name__)
        self.log_service = LogService()
        
        if not self.brave_token:
            raise ValueError("BRAVE_SEARCH_TOKEN nÃ£o encontrado no arquivo .env")

    async def enrich_company(self, company_data: Dict[str, Any]) -> Dict[str, Any]:
        """Enriquece dados da empresa usando a API do Brave Search e/ou scraping do LinkedIn"""
        self.log_service.log_debug("Starting enrichment", {"company_data": company_data})
        
        try:
            # Se jÃ¡ temos a URL do LinkedIn, faz scraping dos dados
            if company_data.get('linkedin_url'):
                self.logger.info(f"LinkedIn URL provided, starting scraping: {company_data['linkedin_url']}")
                return await self._scrape_linkedin_company(company_data['linkedin_url'])
            
            # Se temos o nome da empresa, busca no Brave
            if company_data.get('name'):
                return await self._search_company_with_brave(company_data['name'])
            
            # Se temos o domÃ­nio, busca no Brave
            if company_data.get('domain'):
                return await self._search_company_with_brave(company_data['domain'])
            
            raise ValueError("NecessÃ¡rio fornecer nome da empresa, domÃ­nio ou URL do LinkedIn")
            
        except Exception as e:
            self.log_service.log_debug("Error during enrichment", {"error": str(e)})
            raise ValueError(str(e))

    async def _scrape_linkedin_company(self, linkedin_url: str) -> Dict[str, Any]:
        """Faz scraping da pÃ¡gina da empresa no LinkedIn usando Playwright"""
        self.logger.info(f"Starting LinkedIn scraping for: {linkedin_url}")
        
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True,
                    args=[
                        '--no-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-blink-features=AutomationControlled',
                        '--disable-web-security',
                        '--disable-features=VizDisplayCompositor'
                    ]
                )
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    viewport={'width': 1920, 'height': 1080},
                    locale='en-US'
                )
                
                # Adiciona headers extras para parecer mais humano
                await context.set_extra_http_headers({
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
                })
                
                page = await context.new_page()
                
                self.logger.info(f"Navigating to: {linkedin_url}")
                # Navega com timeout otimizado
                await page.goto(linkedin_url, wait_until="domcontentloaded", timeout=30000)
                
                # Aguarda um pouco para o conteÃºdo carregar
                await page.wait_for_timeout(3000)
                
                self.logger.info("Extracting company data...")
                company_data = await self._extract_company_data(page)
                company_data['linkedin_url'] = linkedin_url
                
                await browser.close()
                
                self.logger.info(f"Successfully scraped company: {company_data.get('name', 'Unknown')}")
                return company_data
                
        except Exception as e:
            self.logger.error(f"Error scraping LinkedIn page: {str(e)}")
            return {
                "name": "Unknown",
                "linkedin_url": linkedin_url,
                "website": None,
                "description": None,
                "industry": None,
                "size": None,
                "founded": None,
                "headquarters": None,
                "employees": [],
                "social_media": [],
                "error": f"Erro ao fazer scraping da pÃ¡gina: {str(e)}"
            }

    async def _extract_company_data(self, page: Page) -> Dict[str, Any]:
        """Extrai dados especÃ­ficos da pÃ¡gina da empresa no LinkedIn"""
        try:
            self.logger.info("Extracting company name...")
            
            # Aguardar elementos especÃ­ficos carregarem
            try:
                await page.wait_for_selector('[data-test-id="about-us__industry"]', timeout=5000)
            except:
                pass  # Continua mesmo se nÃ£o encontrar
                
            try:
                await page.wait_for_selector('[data-test-id="about-us__size"]', timeout=5000)
            except:
                pass  # Continua mesmo se nÃ£o encontrar
                
            try:
                await page.wait_for_selector('[data-test-id="about-us__website"]', timeout=5000)
            except:
                pass  # Continua mesmo se nÃ£o encontrar
                
            try:
                await page.wait_for_selector('[data-test-id="about-us__headquarters"]', timeout=5000)
            except:
                pass  # Continua mesmo se nÃ£o encontrar
                
            try:
                await page.wait_for_selector('[data-test-id="about-us__founded"]', timeout=5000)
            except:
                pass  # Continua mesmo se nÃ£o encontrar
            
            # Scroll para garantir que todo conteÃºdo carregue
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(2000)
            
            # Nome da empresa - mÃºltiplos seletores para maior compatibilidade
            name = await self._safe_extract_text(page, 'h1[data-test-id="org-top-card-summary-info-list__title"]') or \
                   await self._safe_extract_text(page, 'h1.org-top-card-summary__title') or \
                   await self._safe_extract_text(page, 'h1.top-card-layout__title') or \
                   await self._safe_extract_text(page, 'h1')
            
            self.logger.info(f"Company name extracted: {name}")
            
            # DescriÃ§Ã£o
            description = await self._safe_extract_text(page, '[data-test-id="about-us__description"]') or \
                         await self._safe_extract_text(page, '.org-about-us__description') or \
                         await self._safe_extract_text(page, '.break-words')
            
            # IndÃºstria
            industry = await self._safe_extract_text(page, '[data-test-id="about-us__industry"]') or \
                       await self._safe_extract_text(page, '.org-about-us__industry')
            
            # Tamanho da empresa
            size = await self._safe_extract_text(page, '[data-test-id="about-us__size"]') or \
                   await self._safe_extract_text(page, '.org-about-us__company-size')
            
            # Website
            website = await self._safe_extract_attribute(page, '[data-test-id="about-us__website"] a', 'href') or \
                     await self._safe_extract_attribute(page, '.org-about-us__website a', 'href')
            
            # Sede
            headquarters = await self._safe_extract_text(page, '[data-test-id="about-us__headquarters"]') or \
                          await self._safe_extract_text(page, '.org-about-us__headquarters')
            
            # Ano de fundaÃ§Ã£o
            founded = await self._safe_extract_text(page, '[data-test-id="about-us__founded"]') or \
                     await self._safe_extract_text(page, '.org-about-us__founded')
            
            self.logger.info("Company data extraction completed")
            
            return {
                "name": name or "Unknown",
                "website": website,
                "description": description,
                "industry": industry,
                "size": size,
                "founded": founded,
                "headquarters": headquarters,
                "employees": [],  # Pode ser expandido para extrair funcionÃ¡rios
                "social_media": []  # Pode ser expandido para extrair redes sociais
            }
            
        except Exception as e:
            self.logger.error(f"Error extracting company data: {str(e)}")
            return {
                "name": "Unknown",
                "website": None,
                "description": None,
                "industry": None,
                "size": None,
                "founded": None,
                "headquarters": None,
                "employees": [],
                "social_media": []
            }

    async def _safe_extract_text(self, page: Page, selector: str) -> Optional[str]:
        """Extrai texto de um elemento de forma segura"""
        try:
            element = await page.query_selector(selector)
            if element:
                text = await element.inner_text()
                return text.strip() if text else None
        except Exception as e:
            self.logger.debug(f"Could not extract text from selector {selector}: {str(e)}")
        return None

    async def _safe_extract_attribute(self, page: Page, selector: str, attribute: str) -> Optional[str]:
        """Extrai atributo de um elemento de forma segura"""
        try:
            element = await page.query_selector(selector)
            if element:
                attr = await element.get_attribute(attribute)
                return attr.strip() if attr else None
        except Exception as e:
            self.logger.debug(f"Could not extract attribute {attribute} from selector {selector}: {str(e)}")
        return None

    async def _search_company_with_brave(self, search_term: str) -> Dict[str, Any]:
        """Busca empresa usando a API do Brave Search"""
        self.logger.info(f"Searching for company '{search_term}' using Brave Search")
        
        try:
            # Faz a requisiÃ§Ã£o para a API do Brave
            response = requests.get(
                "https://api.search.brave.com/res/v1/web/search",
                headers={
                    "Accept": "application/json",
                    "Accept-Encoding": "gzip",
                    "x-subscription-token": self.brave_token
                },
                params={
                    "q": f'"{search_term}" site:linkedin.com/company'
                },
                timeout=10  # 10 segundos de timeout
            )
            
            if response.status_code != 200:
                raise ValueError(f"Erro na API do Brave: {response.status_code}")
            
            data = response.json()
            
            # Procura pelo primeiro resultado que contenha /company/ na URL
            company_url = None
            company_title = None
            company_description = None
            
            for result in data.get('web', {}).get('results', []):
                url = result.get('url', '')
                if '/company/' in url:
                    company_url = url
                    company_title = result.get('title', '')
                    company_description = result.get('description', '')
                    break
            
            if company_url:
                self.logger.info(f"Found company URL via Brave Search: {company_url}")
                
                # Extrai o nome da empresa do tÃ­tulo ou usa o termo de busca
                company_name = self._extract_company_name(company_title, search_term)
                
                return {
                    "name": company_name,
                    "linkedin_url": company_url,
                    "website": None,
                    "description": company_description,
                    "industry": None,
                    "size": None,
                    "founded": None,
                    "headquarters": None,
                    "employees": [],
                    "social_media": []
                }
            else:
                self.logger.error("No LinkedIn company page found in Brave Search results")
                return {
                    "name": search_term,
                    "linkedin_url": None,
                    "website": None,
                    "description": None,
                    "industry": None,
                    "size": None,
                    "founded": None,
                    "headquarters": None,
                    "employees": [],
                    "social_media": [],
                    "error": "PÃ¡gina da empresa no LinkedIn nÃ£o encontrada"
                }
                
        except requests.Timeout:
            self.logger.error("Timeout during Brave Search API request")
            raise ValueError("Timeout na API do Brave Search")
        except requests.RequestException as e:
            self.logger.error(f"Request error during Brave Search API request: {str(e)}")
            raise ValueError(f"Erro na requisiÃ§Ã£o para API do Brave: {str(e)}")
        except Exception as e:
            self.logger.error(f"Error during Brave Search API request: {str(e)}")
            raise ValueError(f"Erro na API do Brave Search: {str(e)}")

    def _extract_company_name(self, title: str, fallback: str) -> str:
        """Extrai o nome da empresa do tÃ­tulo do resultado"""
        if not title:
            return fallback
        
        # Remove texto comum do LinkedIn
        title = title.replace(" | LinkedIn", "")
        title = title.replace(" - LinkedIn", "")
        title = title.replace(" on LinkedIn", "")
        
        # Se o tÃ­tulo ainda contÃ©m informaÃ§Ã£o Ãºtil, usa ele
        if len(title.strip()) > 0:
            return title.strip()
        
        return fallback

## ğŸ” **ObservaÃ§Ãµes Importantes:**

### **âœ… Funcionando:**
- **Nome**: ExtraÃ­do corretamente
- **URL do LinkedIn**: Encontrada via Brave Search
- **DescriÃ§Ã£o**: ExtraÃ­da com sucesso (incluindo nÃºmero de seguidores)
- **Sem erros**: `"error": null`

### **âš ï¸ Campos vazios (normal para algumas pÃ¡ginas):**
- `website`, `industry`, `size`, `founded`, `headquarters` = `null`

Isso pode acontecer porque:
1. **Layout diferente**: Tesla pode ter layout diferente da Microsoft
2. **Seletores especÃ­ficos**: Alguns elementos podem ter IDs/classes diferentes
3. **ConteÃºdo dinÃ¢mico**: Alguns dados podem carregar via JavaScript apÃ³s nosso scraping

## ğŸ¯ **ComparaÃ§Ã£o dos Resultados:**

| Campo | Microsoft | Tesla | Status |
|-------|-----------|-------|--------|
| **Nome** | âœ… ExtraÃ­do | âœ… ExtraÃ­do | ğŸŸ¢ OK |
| **URL** | âœ… Fornecida | âœ… Encontrada | ğŸŸ¢ OK |
| **DescriÃ§Ã£o** | âœ… Completa | âœ… Completa | ğŸŸ¢ OK |
| **IndÃºstria** | âœ… Software Dev | âŒ null | ğŸŸ¡ VariÃ¡vel |
| **Tamanho** | âœ… 10,001+ | âŒ null | ğŸŸ¡ VariÃ¡vel |
| **Website** | âœ… ExtraÃ­do | âŒ null | ğŸŸ¡ VariÃ¡vel |
| **Sede** | âœ… Redmond | âŒ null | ğŸŸ¡ VariÃ¡vel |

## ğŸ”§ **Melhorias Sugeridas (Opcionais):**

### **1. Seletores mais robustos**
Podemos adicionar mais seletores alternativos para capturar dados em diferentes layouts:
```python
# Exemplo de seletores mais robustos
industry = await self._safe_extract_text(page, '[data-test-id="about-us__industry"]') or \
           await self._safe_extract_text(page, '.org-about-us__industry') or \
           await self._safe_extract_text(page, '[data-field="industry"]') or \
           await self._safe_extract_text(page, '.company-industries') or \
           await self._safe_extract_text(page, 'dd[data-test-id="about-us__industry"]')
```